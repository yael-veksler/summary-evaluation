<?xml version="1.0" encoding="utf-8"?>
<root>
  <!-- 
    Microsoft ResX Schema 
    
    Version 2.0
    
    The primary goals of this format is to allow a simple XML format 
    that is mostly human readable. The generation and parsing of the 
    various data types are done through the TypeConverter classes 
    associated with the data types.
    
    Example:
    
    ... ado.net/XML headers & schema ...
    <resheader name="resmimetype">text/microsoft-resx</resheader>
    <resheader name="version">2.0</resheader>
    <resheader name="reader">System.Resources.ResXResourceReader, System.Windows.Forms, ...</resheader>
    <resheader name="writer">System.Resources.ResXResourceWriter, System.Windows.Forms, ...</resheader>
    <data name="Name1"><value>this is my long string</value><comment>this is a comment</comment></data>
    <data name="Color1" type="System.Drawing.Color, System.Drawing">Blue</data>
    <data name="Bitmap1" mimetype="application/x-microsoft.net.object.binary.base64">
        <value>[base64 mime encoded serialized .NET Framework object]</value>
    </data>
    <data name="Icon1" type="System.Drawing.Icon, System.Drawing" mimetype="application/x-microsoft.net.object.bytearray.base64">
        <value>[base64 mime encoded string representing a byte array form of the .NET Framework object]</value>
        <comment>This is a comment</comment>
    </data>
                
    There are any number of "resheader" rows that contain simple 
    name/value pairs.
    
    Each data row contains a name, and value. The row also contains a 
    type or mimetype. Type corresponds to a .NET class that support 
    text/value conversion through the TypeConverter architecture. 
    Classes that don't support this are serialized and stored with the 
    mimetype set.
    
    The mimetype is used for serialized objects, and tells the 
    ResXResourceReader how to depersist the object. This is currently not 
    extensible. For a given mimetype the value must be set accordingly:
    
    Note - application/x-microsoft.net.object.binary.base64 is the format 
    that the ResXResourceWriter will generate, however the reader can 
    read any of the formats listed below.
    
    mimetype: application/x-microsoft.net.object.binary.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Binary.BinaryFormatter
            : and then encoded with base64 encoding.
    
    mimetype: application/x-microsoft.net.object.soap.base64
    value   : The object must be serialized with 
            : System.Runtime.Serialization.Formatters.Soap.SoapFormatter
            : and then encoded with base64 encoding.

    mimetype: application/x-microsoft.net.object.bytearray.base64
    value   : The object must be serialized into a byte array 
            : using a System.ComponentModel.TypeConverter
            : and then encoded with base64 encoding.
    -->
  <xsd:schema id="root" xmlns="" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:msdata="urn:schemas-microsoft-com:xml-msdata">
    <xsd:import namespace="http://www.w3.org/XML/1998/namespace" />
    <xsd:element name="root" msdata:IsDataSet="true">
      <xsd:complexType>
        <xsd:choice maxOccurs="unbounded">
          <xsd:element name="metadata">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" />
              </xsd:sequence>
              <xsd:attribute name="name" use="required" type="xsd:string" />
              <xsd:attribute name="type" type="xsd:string" />
              <xsd:attribute name="mimetype" type="xsd:string" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="assembly">
            <xsd:complexType>
              <xsd:attribute name="alias" type="xsd:string" />
              <xsd:attribute name="name" type="xsd:string" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="data">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
                <xsd:element name="comment" type="xsd:string" minOccurs="0" msdata:Ordinal="2" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" msdata:Ordinal="1" />
              <xsd:attribute name="type" type="xsd:string" msdata:Ordinal="3" />
              <xsd:attribute name="mimetype" type="xsd:string" msdata:Ordinal="4" />
              <xsd:attribute ref="xml:space" />
            </xsd:complexType>
          </xsd:element>
          <xsd:element name="resheader">
            <xsd:complexType>
              <xsd:sequence>
                <xsd:element name="value" type="xsd:string" minOccurs="0" msdata:Ordinal="1" />
              </xsd:sequence>
              <xsd:attribute name="name" type="xsd:string" use="required" />
            </xsd:complexType>
          </xsd:element>
        </xsd:choice>
      </xsd:complexType>
    </xsd:element>
  </xsd:schema>
  <resheader name="resmimetype">
    <value>text/microsoft-resx</value>
  </resheader>
  <resheader name="version">
    <value>2.0</value>
  </resheader>
  <resheader name="reader">
    <value>System.Resources.ResXResourceReader, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <resheader name="writer">
    <value>System.Resources.ResXResourceWriter, System.Windows.Forms, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089</value>
  </resheader>
  <data name="textBox1.Text" xml:space="preserve">
    <value>[Bearbeiten] Prinzip
Ein Fotoapparat lässt sich geometrisch durch eine Lochkamera modellieren. Bei dieser liegen während der Aufnahme jeder Punkt des aufgenommenen Objektes, das Projektionszentrum (entspricht dem Objektiv der Kamera) sowie der dazugehörige Bildpunkt auf einer Geraden. Wurde der Objektpunkt zweimal von unterschiedlichen Positionen aus aufgenommen, lassen sich bei einer späteren Auswertung mittels der Orientierungen der Kameras der Schnittpunkt der zwei Geraden und damit die Koordinaten des Objektpunktes berechnen. Eine 3D-Rekonstruktion ist somit möglich, wenn in beiden Bildern die Bildpunkte eines Objektpunktes lokalisiert wurden. Die Epipolargeometrie dient zur Unterstützung dieser Lokalisation: ist der Punkt im ersten Bild gegeben, schränkt sich bei bekannter Epipolargeometrie der Suchbereich im zweiten Bild auf eine Linie ein.
In nebenstehender linker Grafik werden die geometrischen Beziehungen verdeutlicht. Dargestellt sind neben den Bild- und Objektpunkten sowie den beiden Projektionszentren die beiden Bildebenen der zwei Kameras. Diese sind vor die Projektionszentren geklappt. Das erleichtert die Darstellung, ändert jedoch nichts an den geometrischen Beziehungen. Der Objektpunkt X bildet sich im Kamerabild�1 auf den Bildpunkt xL ab. Ausgehend von diesem Bildpunkt ist es lediglich möglich, den dazugehörigen Strahl, auf dem X liegt, zu bestimmen. Mögliche Objektpunkte X1, X2 oder X3, die ebenso wie X dem Bildpunkt xL entsprechen, liegen auf diesem Strahl. Dieser Strahl und damit alle möglichen Objektpunkte werden bei der Aufnahme des Objekts von einer anderen Position im zweiten Bild auf einer Geraden abgebildet. Auf diese reduziert sich die Suche nach dem zum Bildpunkt xL korrespondierenden Bildpunkt xR im zweiten Bild.
Mit Hilfe der Epipolargeometrie kann eine einfache Beziehung zwischen korrespondierenden Punkten ohne Kenntnis der Kamerapositionen hergestellt werden. Aus einer bekannten Epipolargeometrie können zwar Informationen über die relative Position der Kameras zueinander abgeleitet werden, zu ihrer Bestimmung ist es jedoch nicht erforderlich, die Kamerapositionen explizit zu kennen. Die Epipolargeometrie hängt nur von den Parametern der Kameras ab und ist damit unabhängig von der Struktur der aufgenommenen Szene.
Zur Beschreibung der Epipolargeometrie und ihrer Elemente existiert eine feste Terminologie. Die Ebene, welche die beiden Projektionszentren der Kameras und der aufgenommene Objektpunkt aufspannen, wird Epipolarebene genannt. Diese schneidet die beiden Bilder in jeweils einer Geraden, der sogenannten Epipolarlinie. Nur auf dieser kann ein korrespondierender Bildpunkt zu einem im anderen Bild gegebenen Punkt liegen. Die Gerade, die die beiden Projektionszentren der Kameras verbindet, durchstößt die beiden Bildebenen in jeweils einem Punkt, dem Epipol. Die beiden Epipole ändern ihre Position im jeweiligen Bild nicht, solange die Lage der Kameras zueinander stabil bleibt. Der Epipol eines Bildes ist gleichzeitig die Abbildung des Projektionszentrums der anderen Kamera. Durch ihn laufen alle Epipolarlinien eines Bildes, er selber kann sich aber je nach Lage der Kameras zueinander außerhalb des eigentlichen Bildes befinden.
Im Bereich der Photogrammetrie wurden und werden zum Teil heute noch die Begriffe Kernstrahlgeometrie, Kernpunkt, Kernebene und Kernlinie anstelle von Epipolargeometrie, Epipol, Epipolarebene und Epipolarlinie verwendet. 
[Bearbeiten] Anwendungen
Die Epipolargeometrie wird vor allem in der projektiven Geometrie, der Photogrammetrie und dem maschinellen Sehen genutzt. Ihr Haupteinsatzzweck ist dabei die Korrespondenzanalyse. Wird zu einem markanten Punkt in einem Bild der korrespondierende im anderen Bild gesucht, so muss bei unbekannter Epipolargeometrie das gesamte Bild untersucht werden. Ist die Epipolargeometrie bekannt, lässt sich die Suche nach dem korrespondierenden Punkt auf die Epipolarlinie einschränken. Das bewirkt eine erhebliche Verkleinerung des Suchraums. Aus diesem Grunde wird die Epipolargeometrie vor allem dort eingesetzt, wo mittels Kameras eine Szene oder ein Objekt dreidimensional analysiert werden muss. Wichtige Einsatzgebiete sind die Vermessung von Werkstücken zur Qualitätsprüfung, die Gebäudeaufnahme bei der Architekturphotogrammetrie oder die Luftbildphotogrammetrie zur Erstellung von Kartenwerken.
[Bearbeiten] Maschinelles Sehen
Die Epipolargeometrie schränkt bei der Korrespondenzsuche zur Objektidentifikation den Suchbereich auf die Epipolarlinien ein und bedingt dadurch eine enorme Rechenzeitersparnis. Gleichzeitig verringert sie die Anzahl von falschen Zuordnungen korrespondierender Punkte durch die Suchraumeinschränkung. Beides ist von großem Vorteil beim maschinellen Sehen. Insbesondere in der autonomen Robotik sind einfache Berechnungen für eine hohe Performance erforderlich, zum Einen wegen der begrenzten Hardware auf mobilen Plattformen und zum Anderen wegen der Notwendigkeit schneller Reaktionen zur Kollisionsvermeidung. So kam bei einem Teilnehmer der DARPA Grand Challenge, ein Wettbewerb unbemannter Landfahrzeuge, die Programmbibliothek OpenCV zum Einsatz, die schnelle Routinen zur Berechnung der Epipolargeometrie und ihrer Anwendung bei der Korrespondenzanalyse beinhaltet. 
[Bearbeiten] Selbstkalibrierung von Kameras
Die 3D-Rekonstruktion einer Szene aus Fotografien setzt voraus, dass die Kalibrierung der Kameras bekannt ist. Da die Epipolargeometrie die projektive Beziehung zwischen zwei Bildern beschreibt, wird sie bei der so genannten Selbstkalibrierung, also der automatischen Ermittlung der Kameraparameter, eingesetzt. Dabei wird die Epipolargeometrie nicht zur Korrespondenzsuche benutzt, sondern rekonstruiert umgekehrt aus bekannten Korrespondenzen die vollständige Kamerakalibrierung.
[Bearbeiten] Geschichte
Die Geschichte der Epipolargeometrie ist eng verbunden mit der Geschichte der Photogrammetrie. Der erste, der die ihr zugrunde liegenden geometrischen Beziehungen analysierte, war der Mathematiker Guido Hauck. Er publiziert 1883 im Journal für die reine und angewandte Mathematik einen Artikel, in dem zum ersten Mal der Begriff Kernpunkt verwendet wurde:
Eine erste umfangreichere Darstellung verfasste 1908 Horst von Sanden im Rahmen seiner Dissertation „Die Bestimmung der Kernpunkte in der Photogrammetrie“. Er beschrieb in dieser Arbeit Methoden zu einer einfacheren und genaueren Bestimmung der Kernpunkte.
Bei der bis zur Einführung der Digitaltechnik vorherrschenden so genannten analogen Photogrammetrie mit optisch-mechanischer Fotografie und Auswertung wurde die Korrespondenzanalyse manuell durchgeführt. Da ein menschlicher Operateur bei genügend Szenenstruktur problemlos korrespondierende Punkte zuordnen kann, wurden die Erkenntnisse kaum angewandt. Erst das Aufkommen der digitalen Photogrammetrie mit digitaler Fotografie und rechnergestützter Offline-Auswertung ab den 1980er�Jahren sowie der steigende Bedarf einer automatisierten Bildauswertung im Bereich des maschinellen Sehens bewirkte eine erneute intensivere Beschäftigung mit der Epipolargeometrie und ihrer Anwendung. Eine erste Arbeit, welche die Neuentdeckung der Thematik belegt, war die Veröffentlichung von Christopher Longuet-Higgins in der Zeitschrift Nature. Seitdem beschäftigen sich viele Wissenschaftler mit der Epipolargeometrie, darunter Huang und Faugeras , Horn sowie Vieville und Lingrand. 
[Bearbeiten] Mathematische Beschreibung
Die Epipolargeometrie stellt eine Beziehung zwischen den Bildkoordinaten korrespondierender Punkte her. Die Bildkoordinaten werden oft in kartesischen Koordinaten, können jedoch auch in affinen Koordinaten angegeben werden. Der Ursprung des Bildkoordinatensystems eines Bildes liegt meist in der Mitte oder der Ecke des Bildes. Bei digitalen Bildern (CCD-Aufnahmen oder gescannte Bilder) können zum Beispiel die Zeile und Spalte der Pixel als Koordinaten verwendet werden. Wenn sich Zeilen- und Spaltenauflösung unterscheiden oder die Achsen des Koordinatensystems nicht rechtwinklig aufeinander stehen, sind diese Koordinaten affin.
Die Beziehung zwischen den Bildkoordinaten korrespondierender Punkte wird durch eine Fundamentalmatrix beschrieben. Mit ihr lässt sich zu einem gegebenen Punkt im ersten Bild die dazugehörige Epipolarlinie im zweiten Bild bestimmen, auf der sich der korrespondierende Punkt befindet.
[Bearbeiten] Homogene Koordinaten und Projektionsmatrix
Die Abbildung der Objektpunkte auf die Bildebene kann mit den in der projektiven Geometrie benutzten homogenen Koordinaten beschrieben werden. Homogene Koordinaten sind gegenüber kartesischen oder affinen Koordinaten um eine Koordinate erweitert und nur bis auf einen Skalierungsfaktor eindeutig. Den zweidimensionalen kartesischen oder affinen Koordinaten entsprechen die homogenen Koordinaten . Die homogenen Koordinaten und repräsentieren denselben Punkt. Entsprechendes gilt für den dreidimensionalen Raum.
Mit homogenen Koordinaten lässt sich die Abbildung der dreidimensionalen Objektpunkte auf die zweidimensionale Bildebene als lineare Funktion beschreiben:
Die kartesischen (oder affinen) Bildkoordinaten erhält man aus x = u / w und y = v / w. Die 3×4-Projektionsmatrix beschreibt die perspektivische Abbildung der Objektpunkte auf die Bildebene. Sie enthält die Daten der Orientierung der Kamera. Da bei dieser Abbildung eine Dimension verlorengeht, ist sie nicht (eindeutig) umkehrbar.
[Bearbeiten] Beziehung zwischen korrespondierenden Punkten
Die Herleitung der Fundamentalmatrix beruht auf der Idee, im ersten Bild einen Punkt auszuwählen, dann einen beliebigen Objektpunkt zu bestimmen, der auf diesen Bildpunkt abgebildet wird, und schließlich dessen Bildpunkt im zweiten Bild zu berechnen. Dieser Punkt und der Epipol befinden sich auf der in der zweiten Bildebene liegenden und zu gehörigen Epipolarlinie und beschreiben sie damit eindeutig.
Ist ein Punkt im ersten Bild gegeben, lässt sich mit Hilfe der zugehörigen Projektionsmatrix der Strahl, auf dem der dazugehörige Objektpunkt liegt, angeben. Der Objektpunkt selbst kann nicht bestimmt werden, da die Entfernung von der Kamera unbekannt ist. Ein beliebiger Punkt auf dem Strahl lässt sich mit der Pseudoinversen berechnen:
Dieser Punkt kann mit der Projektionsmatrix der zweiten Kamera in das zweite Bild abgebildet werden:
Damit ist ein Punkt auf der zu gehörigen Epipolarlinie in Bild 2 bekannt. Ein weiterer Punkt auf dieser Epipolarlinie ist der Epipol , der das Bild des Projektionszentrums der ersten Kamera ist:
Die Epipolarlinie wird in homogenen Koordinaten durch die Geradengleichung beschrieben, wobei als Kreuzprodukt aus zwei Geradenpunkten berechnet werden kann:
Dieses Kreuzprodukt kann mit einer schiefsymmetrischen Matrix auch als Matrizenmultiplikation geschrieben werden:
wobei der Klammerausdruck zu der Fundamentalmatrix zusammengefasst ist. Damit lautet die Gleichung der Epipolarlinie und die Beziehung zwischen korrespondierenden Punkten:
oder:
Diese Gleichung wird als Epipolargleichung bezeichnet.
Ein Spezialisierung der Fundamentalmatrix ist die essentielle Matrix. Diese ergibt sich, wenn normierte Bildkoordinaten verwendet werden, bei denen der Ursprung des kartesischen Bildkoordinatensystems im Hauptpunkt des Bildes liegt. Da diese Bedingung bei der Fundamentalmatrix nicht erfüllt sein muss, kommt sie im Vergleich zur essentiellen Matrix mit weniger Annahmen aus.
[Bearbeiten] Eigenschaften der Fundamentalmatrix
Die Fundamentalmatrix (auch Bifokal-Tensor genannt) enthält die gesamte Information über die Epipolargeometrie. Sie kann auch ohne Kenntnis der Orientierung der Kameras (das heißt ohne Kenntnis der Projektionsmatrizen und sowie des Projektionszentrums ) aus den Bildkoordinaten korrespondierender Punkte bestimmt werden.
Die 3×3-Fundamentalmatrix ist nur bis auf einen Skalierungsfaktor eindeutig bestimmbar, da die Multiplikation der Fundamentalmatrix mit einer beliebigen Zahl ungleich 0 nichts an der Gültigkeit der Epipolargleichung ändert. Damit sind zunächst nur 8 der 9 Elemente unabhängig. Da die Matrix – wie jede schiefsymmetrische -Matrix mit ungeradem n – singulär ist, ist singulär, so dass die Determinante 0 ist. Durch diese zusätzliche Bedingung reduziert sich der Freiheitsgrad der Fundamentalmatrix auf 7.
Mittels der Fundamentalmatrix kann zu einem Punkt im ersten Bild die dazugehörige Epipolarlinie im zweiten Bild berechnet werden:
und umgekehrt zu einem Punkt im zweiten Bild die Epipolarlinie im ersten Bild:
Aus einer gegebenen Epipolarlinie in einem Bild lässt sich nicht der ursprünglichen Punkt im anderen Bild berechnen. Dazu müsste die Fundamentalmatrix invertiert werden, was auf Grund ihrer Singularität nicht möglich ist.
Da der Epipol auf allen Epipolarlinien liegt, muss
für alle gelten, so dass der Epipol und entsprechend der Epipol aus den Gleichungen
bestimmt werden können. Auch aus diesen Gleichungen ist ersichtlich, dass die Determinante der Fundamentalmatrix 0 sein muss, da sonst die Gleichungen nur die Lösungen hätten.
[Bearbeiten] Berechnung
Die Fundamentalmatrix und damit die Epipolargeometrie lässt sich – wie im Abschnitt Beziehung zwischen korrespondierenden Punkten gezeigt – bei bekannter Kalibrierung der beiden Kameras direkt aus beiden Projektionsmatrizen und einem Projektionszentrum berechnen. Da die Berechnung der Fundamentalmatrix meist vor einer Bestimmung der Projektionsmatrizen durchgeführt wird, tritt dieser Fall selten auf. Im Folgenden wird erläutert, wie nur mit Hilfe von Punktkorrespondenzen berechnet werden kann.
Um aus einer Menge korrespondierender Bildpunkte die Fundamentalmatrix zu bestimmen, wird die Epipolargleichung ausmultipliziert:
oder in vektorieller Schreibweise:
mit
Aus n Punktkorrespondenzen kann das folgende homogene lineare Gleichungssystem aufgestellt werden (der obere Index gibt die Punktnummer an):
Da die Koordinaten korrespondierender Punkte die Epipolargleichung erfüllen, sind die Spalten von linear abhängig. Die Matrix hat also im Idealfall höchstens den Rang 8. Dies gilt allerdings bei mehr als 8 Zeilen nur, wenn keine Messungenauigkeiten in den Koordinaten und keine falsch zugeordneten Punktpaare vorliegen. Da nicht vollen Spaltenrang hat, existiert für (abgesehen von der trivialen Lösung ) eine Lösung aus dem Nullraum von .
Im Allgemeinen treten bei der Bestimmung der Korrespondenzen kleinere Messungenauigkeiten auf, da die Bildpunkte nur mit einer endlichen Genauigkeit lokalisiert werden können. Die aus dem Lösungsvektor ermittelte Fundamentalmatrix hat dadurch nicht den Rang 2 und ist somit nicht singulär. Das führt dazu, dass sich die mit dieser Fundamentalmatrix bestimmten Epipolarlinien eines Bildes nicht mehr alle im Epipol schneiden.
In der Praxis kommen zwei Verfahren zur Berechnung der Fundamentalmatrix zur Anwendung, die diese Singularitätsbedingung beachten: der 7-Punkt-Algorithmus und der 8-Punkt-Algorithmus. Bei beiden Verfahren werden meist nicht direkt die gemessenen Koordinaten der Bildpunkte verwendet, sondern die Koordinaten vorher normiert. Dabei werden die Koordinatensysteme in beiden Bildern so verschoben, dass der Ursprung jeweils im Schwerpunkt der Bildpunkte liegt, und dann die Koordinaten so skaliert, dass ihre Werte in der Größenordnung 1 liegen. Mit dieser Normierung kann eine deutliche Verbesserung der Ergebnisse erreicht werden.
[Bearbeiten] 7-Punkt-Algorithmus
Dieses Verfahren benutzt 7 Punktkorrespondenzen zur Berechnung der Fundamentalmatrix . Da nur bis auf einen Faktor eindeutig ist, reichen 7 Punkte zusammen mit der Bedingung aus, um die 9 Elemente von zu bestimmen. Bei 7 Punktkorrespondenzen enthält das Gleichungssystem nur 7 Gleichungen. Es gibt daher zwei linear unabhängige Lösungen und aus dem Nullraum von . Die Fundamentalmatrix wird als Linearkombination der aus und gebildeten Matrizen und bestimmt:
Um jetzt aus der Menge der Lösungen ein auszuwählen, welches den Rang 2 hat, wird ausgenutzt, dass auf Grund der Singularitätsbedingung die Determinante von gleich 0 sein muss:
Diese kubische Gleichung hat mindestens eine und höchstens drei reelle Lösungen α. Mit jeder Lösung α kann eine Fundamentalmatrix berechnet werden. Wenn mehrere Lösungen existieren, sind weitere Punkte erforderlich, um eine eindeutige Lösung zu bestimmen. Es wird die Lösung ausgewählt, bei der auch für weitere Punkte die Epipolargleichung erfüllt oder bei Messungenauigkeiten in den Koordinaten näherungsweise erfüllt ist.
[Bearbeiten] 8-Punkt-Algorithmus
In der Regel sind mehr als 7 Punktkorrespondenzen vorhanden. Der im Folgenden beschriebene 8-Punkt-Algorithmus benötigt mindestens 8 korrespondierende Punktpaare, es können jedoch auch mehr Punkte verwendet werden. Die Idee für dieses Verfahren stammt von Longuet-Higgins. 
Im ersten Schritt wird nur das Gleichungssystem betrachtet, ohne die Bedingung zu berücksichtigen. Im Idealfall hat die Matrix den Rang 8, in der Praxis ist das jedoch bei mehr als 8 Punkten wegen Messungenauigkeiten nicht der Fall, so dass die Lösung nicht aus dem Nullraum von bestimmt werden kann. Stattdessen wird die Lösung mit der Methode der kleinsten Quadrate oder durch die Bestimmung von Eigenwerten ermittelt.
Bei der Methode der kleinsten Quadrate wird so bestimmt, dass minimal ist. Da nur bis auf einen Faktor eindeutig ist, muss eine Bedingung eingeführt werden, z.�B. indem ein Element von gleich 1 gesetzt wird. Das Problem hierbei ist, dass dies nicht gerade ein Element sein darf, das 0 oder sehr klein ist, was a-priori nicht bekannt ist. Man kann jedoch mehrere Möglichkeiten ausprobieren. Bei der zweiten Methode wird ebenfalls minimiert, jedoch mit der Bedingung . Dies führt zu dem Ergebnis, dass die Lösung der Eigenvektor zum kleinsten Eigenwert der Matrix ist.
Die aus der Lösung gebildete Fundamentalmatrix ist im Allgemeinen nicht singulär. Daher muss diese Bedingung in einem zweiten Schritt erfüllt werden. Dazu wird durch eine Singulärwertzerlegung in zerlegt. ist eine Diagonalmatrix, die die Singulärwerte enthält. Der kleinste wird gleich 0 gesetzt, und dann wird aus den Matrizen , und wieder die Fundamentalmatrix berechnet. Da jetzt ein Singulärwert gleich 0 ist, erfüllt die Fundamentalmatrix die Singularitätsbedingung.
Der 8-Punkt-Algorithmus ist ein einfaches Verfahren zur Bestimmung der Fundamentalmatrix, er ist jedoch anfällig gegen Messungenauigkeiten. Dies liegt daran, dass die Singularitätsbedingung der Fundamentalmatrix erst nachträglich erfüllt wird, und dass die minimierte Größe keine physikalische Bedeutung hat. Es gibt weitere Verfahren, die diese Nachteile nicht haben. Diese Verfahren sind jedoch aufwändiger und werden in der Praxis seltener eingesetzt.
[Bearbeiten] Automatische Berechnung
Vor allem beim maschinellen Sehen ist eine automatische Berechnung der Epipolargeometrie notwendig, da zum Beispiel autonome Roboter ohne menschliche Hilfe agieren sollen. Dafür wird im ersten Schritt eine Menge korrespondierender Punkte bestimmt. Dies geschieht mit Hilfe eines Interest-Operators, mit welchem markante Punkte in einem Bild lokalisiert werden können. Sind diese gefunden, wird zu jedem Punkt im ersten Bild der ihm ähnlichste im zweiten Bild bestimmt. Eine Korrespondenzanalyse liefert ein Maß für die Ähnlichkeit. Die Menge korrespondierender Punkte enthält im Allgemeinen auf Grund von Bildrauschen und der unterschiedlichen Perspektive, mit der die beiden Kameras die Szene betrachten, eine größere Anzahl von Fehlzuordnungen und kann daher nicht direkt zur Berechnung der Fundamentalmatrix benutzt werden.
In den folgenden Darstellungen werden markante Punkte sowie das Ergebnis der Korrespondenzanalyse beispielhaft gezeigt. In Bild�3 ist deutlich zu erkennen, dass nicht alle Korrespondenzen richtig bestimmt wurden. Da die Kamera nach der ersten Aufnahme nach rechts geschwenkt wurde, müssten die grünen Striche, welche den Vektor zwischen korrespondierenden Punkten darstellen, etwa horizontal sein. Gerade im Bereich des Baumes links ist dies nicht der Fall, da hier die Blätter alle eine ähnliche Form und Helligkeit haben und damit die Korrespondenzanalyse zu falschen Ergebnissen führt.
Die Fehlzuordnungen müssen vor der Berechnung mittels geeigneter Verfahren zur Separierung und Eliminierung von Ausreißern ausgeschlossen werden. Häufig wird dazu der so genannte RANSAC-Algorithmus verwendet. Dieser Algorithmus kann Fehlzuordnungen in den Punktepaaren aufspüren. Auf die Berechnung von angewandt, besteht er aus folgenden Schritten:
Die Fundamentalmatrix wird anschließend mittels der größten Menge Punktepaare aus Schritt 2 und dem 8-Punkt-Algorithmus bestimmt. Danach kann nochmalig eine Korrespondenzanalyse durchgeführt werden, bei der die berechnete Fundamentalmatrix zum Einsatz kommt (wie beschrieben verkleinert sich der Suchbereich nach korrespondierenden Punkten dadurch auf die Epipolarlinie) und ein niedrigerer Wert für das Ähnlichkeitsmaß akzeptiert wird. Diese letzten beiden Schritte können iterativ wiederholt werden, bis die Zahl der Korrespondenzen stabil ist.
Die folgenden beiden Darstellungen illustrieren das Ergebnis. Die akzeptierten Korrespondenzen sind in der linken wieder als Vektor eingezeichnet. In der rechten Darstellung wurden die Epipolarlinien der markanten Punkte eingezeichnet.
[Bearbeiten] Sonderfälle
Bei bestimmten Positionen der Kameras zueinander kann es zu Singularitäten kommen. Dabei sind zwei Anordnungen insbesondere beim maschinellen Sehen praxisrelevant:
Bei diesen Sonderfällen vereinfacht sich die Korrespondenzsuche, da die Epipolargeometrie bekannt ist. Bei Konfigurationen, in denen Kameraansichten nur näherungsweise parallel sind, kann dieser Zustand durch nachträgliche Rektifizierung hergestellt werden.
[Bearbeiten] Erweiterung auf mehr als zwei Bilder
Die Trifokalgeometrie ist die Erweiterung der Epipolargeometrie auf drei Bilder. Ist die Position eines Objektpunktes in zwei Bildern bekannt, so ist seine Position im dritten Bild der Schnittpunkt der beiden Epipolarlinien. Damit existiert im Unterschied zum Bildpaar ein eindeutiges Ergebnis, sofern der Punkt nicht in der Trifokalebene (die Ebene, die aus den drei Projektionszentren gebildet wird) liegt oder die drei Projektionszentren auf einer Linie liegen. Die Anordnung, bei der ein 3D-Punkt auf der Trifokalebene liegt, wird als singulärer Fall bezeichnet.
Es ist möglich, die Epipolargeometrie auf mehr als drei Bilder auszuweiten. Dies ist in der Praxis nur bei vier Ansichten üblich. Hier existiert der sogenannte quadrifokale Tensor, der die Beziehung von Bildpunkten und Linien zwischen diesen Bildern beschreibt. Für mehr als vier Ansichten wurden jedoch keine mathematischen Beziehungen untersucht, da die Komplexität der Modellierung und Berechnung wesentlich höher ist und in den meisten Anwendungen beginnend mit der fünften Kamera der zusätzliche Informationsgewinn nur noch gering ist.
[Bearbeiten] Abweichungen vom Modell der Lochkamera
Die beschriebene Beziehung zwischen korrespondierenden Bildpunkten, die sich durch die Fundamentalmatrix vollständig beschreiben lässt, gilt nur für Fotoaufnahmen, die durch eine Lochkamera modelliert werden können. Treten beispielsweise Verzerrungen bei der Abbildung auf die Bildebene auf oder ist die Bildfläche keine Ebene, sind diese Abweichungen bei der Epipolargeometrie zu berücksichtigen. Insbesondere sind die Epipolarlinien, auf denen der zu einem Bildpunkt im ersten Bild korrespondierende Bildpunkt im zweiten Bild zu suchen ist, keine Geraden.
[Bearbeiten] Verzeichnung
Nur bei hochwertigen Objektiven tritt kaum eine Verzeichnung auf. Bei anderen Objektiven und entsprechenden Genauigkeitsanforderungen ist die Verzeichnung zu berücksichtigen. Die Verzeichnung kann oft als radiale Verzeichnung modelliert werden, d.�h. sie nimmt mit dem Abstand vom Verzeichnungszentrum (meist in der Nähe der Bildmitte) zu.
Ist eine Kamera entsprechend kalibriert und die Verzeichnung bekannt, können die Bilder korrigiert werden. Mit diesen korrigierten Bildern kann dann wie mit verzeichnungefreien Bildern gearbeitet werden.
Unter bestimmten Voraussetzungen kann die Verzeichnung in einer erweiterten Fundamentalmatrix berücksichtigt werden. Dabei wird für jedes Bild eine Verzeichnung angenommen, die durch jeweils einen (unbekannten) Parameter beschrieben werden kann und die dem Ersetzen der ebenen Bildfläche durch eine quadratische Fläche im dreidimensionalen projektiven Raum entspricht. Die Beziehung zwischen zwei korrespondierenden Punkten wird dann durch eine -Fundamentalmatrix mit 9 Freiheitsgraden beschrieben. 
[Bearbeiten] Panoramakameras
Bei Panoramakameras, die Aufnahmen mit großem Bildwinkel ermöglichen, kann die Aufnahmegeometrie nicht durch eine Lochkamera mit einer ebenen Bildfläche modelliert werden. Die Beschreibung der Epipolargeomatrie hängt von der Art der Panoramakamera ab. Besteht die Kamera beispielsweise aus einer Lochkamera und einem hyperbolischem Spiegel, so bilden die Epipolarlinien Kegelschnitte.</value>
  </data>
  <data name="label4.Text" xml:space="preserve">
    <value>Ein Fotoapparat lässt sich geometrisch durch 
eine Lochkamera modellieren. Bei dieser liegen 
während der Aufnahme jeder Punkt des 
aufgenommenen Objektes, das Projektionszentrum
 (entspricht dem Objektiv der Kamera) sowie der
 dazugehörige Bildpunkt auf einer  Geraden. Wurde
 der Objektpunkt zweimal von unterschiedlichen 
Positionen aus aufgenommen, lassen sich bei einer
 späteren Auswertung mittels der Orientierungen der
 Kameras der Schnittpunkt der zwei Geraden und damit
 die Koordinaten des Objektpunktes berechnen. 
Eine 3D-Rekonstruktion ist somit möglich, wenn
 in beiden Bildern die Bildpunkte eines Objektpunktes 
lokalisiert wurden. Die Epipolargeometrie dient zur 
Unterstützung dieser Lokalisation: ist der Punkt im ersten 
Bild gegeben, schränkt sich bei bekannter 
</value>
  </data>
  <data name="label7.Text" xml:space="preserve">
    <value>Die Epipolargeometrie (selten auch Kernstrahlgeometrie) ist
ein mathematisches Modell aus der Geometrie, das die 
geometrischen Beziehungen zwischen verschiedenen
 Kamerabildern des gleichen Objekts darstellt. 
Mit ihrer Hilfe lässt sich die Abhängigkeit zwischen 
korrespondierenden Bildpunkten beschreiben – also den
 Punkten, die ein einzelner Objektpunkt in den beiden
 Kamerabildern erzeugt. Obwohl ihre Grundlagen 
bereits 1883 von Guido Hauck und 1908 von Horst von 
Sanden untersucht wurden, gelangte die Epipolargeometrie 
erst mit der automatischen Auswertung digitaler Bilder vor 
allem im Bereich des maschinellen Sehens zu größerer Bedeutung.
Vornehmlich wird die Epipolargeometrie bei der Gewinnung von
 3D-Informationen aus Bildern eingesetzt.
 Dabei unterstützt sie die Korrespondenzanalyse, also die 
Zuordnung korrespondierender Punkte, 
und reduziert den erforderlichen Suchaufwand erheblich.</value>
  </data>
</root>